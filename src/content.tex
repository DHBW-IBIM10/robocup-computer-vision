\title{\papertitle}

\author{Rocco Schulz and Robert Wawrzyniak}
	
\publishers{Corporate State University\\Baden-Wuerttemberg - Stuttgart}

\date{
\vspace{0.6cm}
provided on 6 May 2013\\
\vspace{0.6cm}
School of: Business\\
\vspace{0.6cm}
Program: International Business Information Management\\
\vspace{0.6cm}
Course: WWI2010I\\
\vspace{0.6cm}
}





% DOCUMENT
\renewcommand{\baselinestretch}{1.5}\normalsize
\begin{document}
\pagestyle{scrheadings}

% roman numerals
\renewcommand{\thepage}{\Roman{page}}
% page numbers centered on top:
\chead{\pagemark}
\cfoot{}

%----------------------------------------------------------------------------
% Title Page
%----------------------------------------------------------------------------

% no page numbering
\thispagestyle{empty}
% include title page
\input{title_page}


%  \begin{abstract}
%  \vspace{1.6cm}
% % \textbf{\abstractname}: 
%  \end{abstract}


%----------------------------------------------------------------------------
% Table of Contents
%----------------------------------------------------------------------------
\renewcommand{\baselinestretch}{1.4}\normalsize
\tableofcontents
\renewcommand{\baselinestretch}{1.5}\normalsize
\newpage


%----------------------------------------------------------------------------
% Abbreviations
%----------------------------------------------------------------------------
% List needs to be indexed after each change.
% This is done by executing the following command:
% ~$ makeindex [filename].nlo -s nomencl.ist -o [filename].nls
\printnomenclature
\addcontentsline{toc}{section}{List of Abbreviations}
\input{nomenclature.tex}

\newpage

%----------------------------------------------------------------------------
% List Of Tables
%----------------------------------------------------------------------------
\listoftables
\addcontentsline{toc}{section}{\listtablename}
\newpage


%----------------------------------------------------------------------------
% List of Listings
%----------------------------------------------------------------------------
%\lstlistoflistings
\listoflistings
\addcontentsline{toc}{section}{List of Listings}
\newpage

% Arabic numerals for page numbering
\renewcommand{\thepage}{\arabic{page}}

% Set page number to 1: 
\setcounter{page}{1} 


%----------------------------------------------------------------------------
% Intro
%----------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}




\subsection{Objectives}
\label{sec:objectives}



\subsection{Methodology and Structure}
\label{sec:methodology}



%----------------------------------------------------------------------------
% Theoretical Foundation
%----------------------------------------------------------------------------
\newpage
\section{RoboCup \label{sec:robo}}
Robots play soccer.
Environment is dynamic.

Long Term Goal “By mid-21st century, a team of fully autonomous humanoid robot
soccer players shall win the soccer game, comply with the official rule of the
FIFA, against the winner of the most recent World
Cup.”\footcite[Cf.][]{robo_objectives}

Computational challenges are in the environment of the RoboCup.
Comparison to chess, where computers are superior already:

\begin{table}[htbp]
\centering
\begin{savenotes}
\begin{tabular*}{0.7\textwidth}{p{0.25\textwidth} p{0.2\textwidth} p{0.2\textwidth}}
\toprule
                    &\textbf{Chess} & \textbf{Robocup} \\
\midrule 
Environment         & static		& dynamic \\
State change        & turn taking   & real time \\
Info. accessibility & complete      & incomplete \\
Sensor readings     & symbolic      & non-symbolic \\
Control             & central       & distributed \\
\bottomrule 
\end{tabular*}
  \caption[Comparison of Chess and Robocup]{Comparison of Chess and Robocup\footcite[][]{robo_objectives}}
  \label{tab:chess_comparison}
\end{savenotes}
\end{table}

\subsection{RoboCup Leagues \label{sec:robo-leagues}}

%TODO: add short description for each league

\paragraph{Humanoid}
In the Humanoid League autonomous robots with human-like bodies play soccer
against each other.
Robots may only use sensors that cover human senses to perceive their
environment. Additional technical challenges in this league are proper running and ball
kicking while keeping the balance. Robots need to localize theirselves on the
field using the available sensors.
There are three categories within the humanoid league: KidSize (30-60cm height),
TeenSize (100-120cm) and AdultSize (130cm and taller).\footcite[Cf.][]{robo_humanoid_wiki}
 
\paragraph{Middle Size}
In the Middle Size League autonomous robots with zylindric bodies of no more
than 50cm diameter play soccer in teams of up to 6 players. Robots may use
wireless networking to communicate and all sensors are deployed on-board.\footcite[Cf.][]{robo_ms}
 
\paragraph{Simulation}
``In the 2D Simulation League, two teams of eleven autonomous software programs
(called agents) each play soccer in a two-dimensional virtual soccer stadium
represented by a central server, called SoccerServer.''\footcite[][]{robo_simu_wiki}
Agents receive relative and noisy input from their virtual sensors which they can use to
calculate and perform desired actions. There is also a 3D Simulation League which differs
from the 2D League by adding a third dimension and more complex physical
models.\footcite[Cf.][]{robo_simu_wiki}
 
\paragraph{Small Size}
In the Small Size League teams of five robots each compete on a field of 5.05m~x 4.05m.
Robots must fit in a circle with a diameter of 18cm and must not be higher than 15cm.
Robots are not fully autonomous as they can be controlled by off-field computers which receive
game information via a central software server which tracks locations and other parameters
of the game.\footcite[Cf.][]{robo_ssl_wiki}
This software is called SSL-Vision and will be covered in further detail in section
\ref{sec:ssl-vision}.
 
\paragraph{Standard Platform}
In the Standard Platform League all teams compete with identical
robots.\footcite[Cf.][]{robo_std_wiki} ``The robots operate fully autonomously,
i.e. there is no external control, neither by humans nor by computers. The
current standard platform used is the humanoid NAO by Aldebaran
Robotics.''\footcite[][]{robo_std_wiki}


\subsection{Related Research Areas \label{sec:robo-research}}
Various research areas are relevant for the further development of the RoboCup
and the capabilities of the robots used in the matches. An overview of the most
important research areas is given in the list below:\footcite[Cf.][]{robo_objectives}
\begin{itemize}
  \item real-time sensor fusion
  \item reactive behavior
  \item strategy acquisition
  \item learning
  \item real-time planning
  \item multi-agent systems
  \item context recognition
  \item computer vision
  \item strategic decision-making
  \item motor control
  \item intelligent robot control
\end{itemize}

The main role of computer vision is the detection of game objects and object
localization on the field and will be described in further detail in the next
section.

\newpage
\section{Computer Vision at RoboCup \label{sec:cv-robo}}

Computer vision is used in all leagues of the RoboCup.
The leagues can be categorized in fully autonomously (distributed) and centrally
controlled robots. The Small Size League fits into the latter of these two categories.

\subsection{Centralized}
In the Small Size League a centralized computer vision system captures images
of the game and pre-processes them before broadcasting the information to the teams
for further processing.

Robots and the ball are tracked via markings. A camera above the field sends
data to a computer which does real time analysis of image data to determine
positions and directions using COMPUTER VISION

``All objects on the field are tracked by a standardized vision system that
processes the data provided by two cameras that are attached to a camera bar
located 4m above the playing surface. The vision system - called SSL-Vision - is
an open source project maintained by the league's community."\footcite[Cf.][]{robo_ssl_wiki}

Robots and the ball are tracked via markings. A camera above the field sends
data to a computer which does real time analysis of image data to determine
positions and directions using COMPUTER VISION

\begin{savenotes}
\begin{figure}[htbp]
\begin{center}
  \includegraphics[width=0.6\textwidth]{img/ssl_dataflow.png}
  \caption[Data flow in SSL camera setup]{Data flow in SSL camera setup\footcite[][]{robo_ssl_wiki}}
  \label{fig:ssl_dataflow}
\end{center}
\end{figure}
\end{savenotes}

\subsection{Distributed / Autonomous}
for other leagues. each robot has own cv.
In most other leagues robots have to rely on their own sensing, however they may
communicate with each other over the air.
Less computation power available, CV data needs to be translated to position,
etc. Robots need to keep track of other players and the ball + movements and
velocity of objects.



\newpage
\section{SSL-Vision \label{sec:ssl-vision}}


\subsection{Application Overview \label{sec:ssl-overview}}
SSL-Vision is the open source software which is used in the Small Size League to
track game objects on the field. It is written in C++ and uses multiple threads
for best performance. The software comes with a graphical user interface (GUI)
which can be used for configuration and monitoring of input and output data.

The software has a multi-camera stack where one thread is assigned for each camera.
For each camera plugins can be enabled to perform various image processing
tasks. These plugins can operate together by using common interfaces for data
transfer.

SSL-Vision receives raw video streams from various cameras as input. The
computed information, such as robots identified by id and their appropriate
coordinates on the field are broadcasted to the teams' servers for further
processing and decision making. For testing and development purposes it is also
possible to use filestreams as input for the system.

\subsection{The Image Processing Flow}
The processing stack for the Small Size League domain follows a multi-stage
approach which is described in this section.\\
SSL-Vision relies on colored markers to identify robots on the field.
Each robot on the field is uniquely identifiable by a colored marker that
consists of a combination for team identification as well as additional color
elements to provide uniqueness for each robot.\footcite[Cf.][5]{zickler_ssl_vision}
SSL-Vision needs to determine robots' real-world locations (as opposed to the
location in the image), directions and IDs.
In order to get these information different algorithms and techniques need to be
applied in real time. One of these is color segmentation, which serves as a 
base for the pattern detection step in the overall processing flow.


\subsubsection{Color Segmentation}
Color segmentation is done with plugins for color thresholding, runlength-encoding,
region extraction and region sorting.\footcite[Cf.][]{zickler_ssl_vision}

\paragraph{Color thresholding}
Color thresholding is done via a lookup table which maps from the input image's
3d color space (YUV) to a unique color label which represents any of the marker
colors, the ball color or other desired colors.\footcite[Cf.][p. 4 et sq.]{zickler_ssl_vision}
The plugin uses YUV for the color space mapping, which is for instance used
in PAL and NTSC videos. The \textit{Y} in YUV represents lumination and
\textit{U/V} is used for the color representation.

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
                \includegraphics[width=\textwidth]{img/YUV.png}
                \caption{YUV colorspace}
                \label{fig:yuv_normal}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
                \includegraphics[width=\textwidth]{img/YUV_LUT.png}
                \caption{Mapped YUV colorspace}
                \label{fig:yuv_mapped}
        \end{subfigure}

        \caption{Exemplary YUV colorspace mapping}\label{fig:yuv}
\end{figure}

Fig. \ref{fig:yuv} illustrates how the color mapping works. Fig.
\ref{fig:yuv_normal} shows the normal YUV colorspace and Fig.
\ref{fig:yuv_mapped} shows the mapped colorspace which replaces regions in the
colorspace with a single color value. The colors in the input images are
replaced acordingly to the color mappings before further processing by the other
plugins takes place.


\paragraph{Runlength encoding}

\begin{itemize}
  \item the line by line runlength encoding is applied on the thresholded image to speed up the region extraction that follows (source code)
  \item simple data compression technique
  \item Algorithm for runlength encoding of images:
for each row of pixels:
remember pixel value and go to next pixel;
if pixel value equals previous pixel, merge pixels
  \item Example from Wikipedia:
“(...) screen containing plain black text on a solid white background. There will be many long runs of white pixels in the blank space, and many short runs of black pixels within the text. Let us take a hypothetical single scan line, with B representing a black pixel and W representing white:
WWWWWWWWWWWWBWWWWWWWWWWWWBBBWWWWWWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWWWWW
If we apply the run-length encoding data compression algorithm to the above hypothetical scan line, we get the following:
12W1B12W3B24W1B14W”
  \item works well due to the previous color thresholding
\end{itemize}

\paragraph{Region extraction}

pixels are only connected horizontally (lines)\\
vertical connections needed to get regions (polygons)\\
region extraction uses tree-based union find algorithm to traverse the
runlength-encoded image and merge neighboring runs of similar colors. (plugin
source code, region extraction source code)\\



Also see
\url{http://code.google.com/p/ssl-vision/source/browse/trunk/src/app/plugins/plugin_find_blobs.cpp}
and 
\url{http://code.google.com/p/ssl-vision/source/browse/trunk/src/shared/cmvision/cmvision_region.cpp#97}

Union find algorithm:\\
consists of find() and union()\footcite[Cf.][]{sedgewick_union_find}\\
good explanation at:
\footcite[Cf.][]{wa_union_find} \\

bounding boxes and centroids of all merged regions are then computed and finally
sorted by color and size\\

centroids will later be used for location determination


\subsubsection{Pattern Detection}


%----------------------------------------------------------------------------
% Closing
%----------------------------------------------------------------------------

\clearpage
\section{Conclusion and Outlook}
\label{sec:conclusion}
SSL Vision is pretty mature.



%----------------------------------------------------------------------------
% APPENDIX
%----------------------------------------------------------------------------
% Appendix sections need to be within the subappendices environment.
% Use the command \appsection{title} instead of \section to introduce each
% appendix. This will add each appendix to the list of appendices.

% sets the appendix environment and resets the section counters
\newpage \begin{appendices} 
\appendixtocon %adds an 'Appendices' entry to the toc

\appendixpage %prints the title on the page

\subsection*{\listappendixname}
%--------------------------------
% style of the \listofappendices command is defined in header.tex
\listofappendices

% begin appendices on a new page
\newpage

%start environment for subappendices, so that new sections are formatted as
%subsections of appendix
\begin{subappendices}
\renewcommand{\setthesubsection}{\arabic{subsection}:}%

\appsection{Source Code}
\label{apx:code-template}


% close the appendices environment
\end{subappendices}
\end{appendices}
